{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1、概要"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'skimage'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e789ac95ecb1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mskimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimshow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'skimage'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from skimage.io import imread, imshow\n",
    "import cv2\n",
    "\n",
    "%matplotlib inline\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "\n",
    "from subprocess import check_output\n",
    "print(check_output([\"ls\", \"../input/train\"]).decode(\"utf8\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2、准备数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查看目标变量的分布。当分布不平衡时，根据评分标准和具体模型的使用不同，可能会严重影响性能。\n",
    "\n",
    "对 Numerical Variable，可以用 Box Plot 来直观地查看它的分布。\n",
    "\n",
    "对于坐标类数据，可以用 Scatter Plot 来查看它们的分布趋势和是否有离群点的存在。\n",
    "\n",
    "对于分类问题，将数据根据 Label 的不同着不同的颜色绘制出来，这对 Feature 的构造很有帮助。\n",
    "\n",
    "绘制变量之间两两的分布和相关度图表。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "basepath = '../input/train/'\n",
    "\n",
    "all_cervix_images = []\n",
    "\n",
    "for path in sorted(glob(basepath + \"*\")):\n",
    "    cervix_type = path.split(\"/\")[-1]\n",
    "    cervix_images = sorted(glob(basepath + cervix_type + \"/*\"))\n",
    "    all_cervix_images = all_cervix_images + cervix_images\n",
    "\n",
    "all_cervix_images = pd.DataFrame({'imagepath': all_cervix_images})\n",
    "all_cervix_images['filetype'] = all_cervix_images.apply(lambda row: row.imagepath.split(\".\")[-1], axis=1)\n",
    "all_cervix_images['type'] = all_cervix_images.apply(lambda row: row.imagepath.split(\"/\")[-2], axis=1)\n",
    "all_cervix_images.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 图像类型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在我们有了一个方便的dataframe数据，我们可以对数据进行一些聚合。让我们先看看每个子宫颈类型和它们的文件类型有多少个图像。\n",
    "\n",
    "所有的文件都是JPG格式的，2型是最常见的一种，在训练数据中，总共有略多于50%的数据，1型在训练数据中略少于20%。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('We have a total of {} images in the whole dataset'.format(all_cervix_images.shape[0]))\n",
    "type_aggregation = all_cervix_images.groupby(['type', 'filetype']).agg('count')  # agg：聚合\n",
    "type_aggregation_p = type_aggregation.apply(lambda row: 1.0*row['imagepath']/all_cervix_images.shape[0], axis=1)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(10, 8))\n",
    "\n",
    "type_aggregation.plot.barh(ax=axes[0])  # barh:水平条形图\n",
    "axes[0].set_xlabel(\"image count\")\n",
    "type_aggregation_p.plot.barh(ax=axes[1])\n",
    "axes[1].set_xlabel(\"training size fraction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查看每个类型的文件，以了解图像的外观。\n",
    "\n",
    "这些图像在样式上似乎有所不同，前两个样本只有一个圆形区域和实际图像，最后一个样本在一个矩形中有图像。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,8))\n",
    "\n",
    "i = 1\n",
    "for t in all_cervix_images['type'].unique():\n",
    "    ax = fig.add_subplot(1,3,i)\n",
    "    i += 1\n",
    "    f = all_cervix_images[all_cervix_images['type'] == t]['imagepath'].values[0]\n",
    "    plt.imshow(plt.imread(f))\n",
    "    plt.title('sample for cervix {}'.format(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 图像尺寸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "查看下有多少种不同尺寸（shape）的图像。为了减少运行时间，每个类只需要一个子样本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict  # 使用dict时，如果引用的Key不存在，就会抛出KeyError。如果希望key不存在时，返回一个默认值，就可以用defaultdict\n",
    "\n",
    "images = defaultdict(list)\n",
    "\n",
    "for t in all_cervix_images['type'].unique():\n",
    "    sample_counter = 0\n",
    "    for _, row in all_cervix_images[all_cervix_images['type'] == t].iterrows():\n",
    "        #print('reading image {}'.format(row.imagepath))\n",
    "        try:\n",
    "            img = imread(row.imagepath)\n",
    "            sample_counter +=1\n",
    "            images[t].append(img)\n",
    "        except:\n",
    "            print('image read failed for {}'.format(row.imagepath))\n",
    "        if sample_counter > 35:  # 每种图取36幅，总共取108幅\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for t in all_cervix_images['type'].unique():\n",
    "    t_ = pd.DataFrame(\n",
    "        {\n",
    "            'nrows': list(map(lambda i: i.shape[0], images[t])),\n",
    "            'ncols': list(map(lambda i: i.shape[1], images[t])),\n",
    "            'nchans': list(map(lambda i: i.shape[2], images[t])),\n",
    "            'type': t\n",
    "        }\n",
    "    )\n",
    "    dfs.append(t_)\n",
    "\n",
    "shapes_df = pd.concat(dfs, axis=0)  # 合并\n",
    "# 获取每种图各尺寸的数目统计\n",
    "shapes_df_grouped = shapes_df.groupby(by=['nchans', 'ncols', 'nrows', 'type']).size().reset_index().sort_values(['type', 0], ascending=False)\n",
    "shapes_df_grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "样本中的所有图像都有三个通道，现在可以忽略这些信息。建立一个barplot，通过子宫颈类型了解图像尺寸的分布。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shapes_df_grouped['size_with_type'] = shapes_df_grouped.apply(lambda row: '{}-{}-{}'.format(row.ncols, row.nrows, row.type), axis=1)\n",
    "shapes_df_grouped = shapes_df_grouped.set_index(shapes_df_grouped['size_with_type'].values)\n",
    "shapes_df_grouped['count'] = shapes_df_grouped[[0]]\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "#shapes_df_grouped['count'].plot.barh(figsize=(10,8))  # pandas(为什么不需要指定y？)\n",
    "sns.barplot(x=\"count\", y=\"size_with_type\", data=shapes_df_grouped)  # seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3、数据分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 TSNE embedding（数据降维）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TSNE(t分布随机相邻嵌入)方法相比PCA等线性降维方法，能有效将数据投影到低维空间并保持严格的分割界面（维持距离）;缺点是计算复杂度大,一般推荐先线性降维然后再用t-SNE降维。**\n",
    "\n",
    "现在我们将获取所有的示例图像，重新缩放它们并将它们转换为灰度图像。结果将产生一个矩阵，其中每一行都是灰度图像的扁平像素。\n",
    "\n",
    "由于原始图像是高分辨率的，因此将尺寸范围缩小到100*100将导致信息的大量丢失。因此降维到两个维度可能不会具有良好的结构，这可以通过单独观察宫颈癌类型的分布看到。\n",
    "\n",
    "同时，我们在每个阶段中只提供很少的图像，TSNE可以用来在这些图像上做一个维持距离的降维。\n",
    "\n",
    "我添加了一个选项，选择将它们转换为灰度，然后将它们传递给TSNE。每一个默认图像将保留其RGB信息，因此将被转换为100*100*3 = 30000维向量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_image(img, rescaled_dim, to_gray=False):\n",
    "    resized = cv2.resize(img, (rescaled_dim, rescaled_dim), cv2.INTER_LINEAR) # INTER_LINEAR：线性插值\n",
    "\n",
    "    if to_gray:\n",
    "        resized = cv2.cvtColor(resized, cv2.COLOR_RGB2GRAY).astype('float')\n",
    "    else:\n",
    "        resized = resized.astype('float')\n",
    "\n",
    "    normalized = cv2.normalize(resized, None, 0.0, 1.0, cv2.NORM_MINMAX) # NORM_MINMAX：线性归一化\n",
    "    timg = normalized.reshape(1, np.prod(normalized.shape)) # 连乘\n",
    "\n",
    "    return timg / np.linalg.norm(timg)  # L2\n",
    "\n",
    "rescaled_dim = 100\n",
    "\n",
    "all_images = []\n",
    "all_image_types = []\n",
    "\n",
    "for t in all_cervix_images['type'].unique():\n",
    "    all_images = all_images + images[t]\n",
    "    all_image_types = all_image_types + len(images[t])*[t]\n",
    "\n",
    "# - normalize each uint8 image to the value interval [0, 1] as float image\n",
    "# - rgb to gray\n",
    "# - downsample image to rescaled_dim X rescaled_dim\n",
    "# - L2 norm of each sample = 1\n",
    "gray_all_images_as_vecs = [transform_image(img, rescaled_dim) for img in all_images]  # list\n",
    "print(np.array(gray_all_images_as_vecs).shape)  # (108, 1, 30000)\n",
    "\n",
    "gray_imgs_mat = np.array(gray_all_images_as_vecs).squeeze()  # 压缩维度（移除长度为1的轴），能将矩阵变向量\n",
    "all_image_types = np.array(all_image_types)\n",
    "gray_imgs_mat.shape, all_image_types.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3D t-SNE宫颈指标**\n",
    "现在让我们将100*100*3图像投影到三维图像上，以检查低维图案。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "tsne = TSNE(\n",
    "    n_components=3, # 嵌入空间的维数\n",
    "    init='random', # pca\n",
    "    random_state=101,\n",
    "    method='barnes_hut',\n",
    "    n_iter=500,\n",
    "    verbose=2\n",
    ").fit_transform(gray_imgs_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "# https://plot.ly/python/3d-scatter-plots/\n",
    "trace1 = go.Scatter3d(\n",
    "    x=tsne[:,0],\n",
    "    y=tsne[:,1],\n",
    "    z=tsne[:,2],\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        sizemode='diameter',\n",
    "        color = preprocessing.LabelEncoder().fit_transform(all_image_types),\n",
    "        colorscale = 'Portland',\n",
    "        colorbar = dict(title = 'cervix types'),\n",
    "        line=dict(color='rgb(255, 255, 255)'),\n",
    "        opacity=0.9\n",
    "    )\n",
    ")\n",
    "\n",
    "data=[trace1]\n",
    "layout=dict(height=800, width=800, title='3D embedding of images')\n",
    "fig=dict(data=data, layout=layout)\n",
    "py.iplot(fig, filename='3DBubble')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以清楚地看到，有一个大的各种各样的聚类图和一些非常遥远的离群值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for t in all_cervix_images['type'].unique():\n",
    "    tsne_t = tsne[np.where(all_image_types == t), :][0]\n",
    "    plt.scatter(tsne_t[:, 0], tsne_t[:, 1]) # 散点图\n",
    "plt.legend(all_cervix_images['type'].unique())  # 显示图例"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TSNE 用作图像聚类**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "现在让我们使用压缩后的图像和TSNE的保持距离转换来理解图集。\n",
    "\n",
    "为此，我们将使用matplotlib来替换先前的红、绿和蓝色的点，并将实际图像输入到TSNE转换中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "def imscatter(x, y, images, ax=None, zoom=0.01):\n",
    "    ax = plt.gca()\n",
    "    images = [OffsetImage(image, zoom=zoom) for image in images] # 缩放图\n",
    "    artists = []\n",
    "    for x0, y0, im0 in zip(x, y, images):\n",
    "        ab = AnnotationBbox(im0, (x0, y0), xycoords='data', frameon=False) # 标注框\n",
    "        artists.append(ax.add_artist(ab))\n",
    "    ax.update_datalim(np.column_stack([x, y])) # 堆叠显示\n",
    "    ax.autoscale()\n",
    "    #return artists\n",
    "\n",
    "nimgs = 60\n",
    "plt.figure(figsize=(10,8))\n",
    "imscatter(tsne[0:nimgs,0], tsne[0:nimgs,1], all_images[0:nimgs]) # 坐标里绘制图像"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 成对图像距离的聚类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从纯数值的角度来看图像是如何相互联系的，现在我们来看看成对图像的距离。为此，我们将使用scipy的pdist方法。\n",
    "\n",
    "黄色的聚集区域告诉我们有一些图像与我们读取的训练图像样本中的所有其他图像具有相对较高的距离。在clustermap的左侧和顶部，我们为每行每列找到了三种颜色之一，该颜色表示子宫颈的类型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pal = sns.color_palette(\"hls\", 3)  # 调色板。HLS：Hue(色相)、Luminance(亮度)、Saturation(饱和度)\n",
    "sns.palplot(pal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "sq_dists = squareform(pdist(gray_imgs_mat))  # pdist：计算成对图像的矩阵距离，squareform：转换为对称矩阵，对角线为0（自己和自己的距离）\n",
    "\n",
    "all_image_types = list(all_image_types)\n",
    "\n",
    "d = {\n",
    "    'Type_1': pal[0], # Red\n",
    "    'Type_2': pal[1], # Green\n",
    "    'Type_3': pal[2] # Blue\n",
    "}\n",
    "\n",
    "# translate each sample to its color\n",
    "colors = list(map(lambda t: d[t], all_image_types))\n",
    "\n",
    "# http://seaborn.pydata.org/generated/seaborn.clustermap.html?highlight=clustermap#seaborn.clustermap\n",
    "sns.clustermap(  # 分层热图\n",
    "    sq_dists,\n",
    "    figsize=(12,12),\n",
    "    row_colors=colors, col_colors=colors,\n",
    "    cmap=plt.get_cmap('viridis')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 这是非聚合的距离矩阵\n",
    "\n",
    "mask = np.zeros_like(sq_dists, dtype=np.bool)  # 返回和输入矩阵类似但用0填充的矩阵\n",
    "mask[np.triu_indices_from(mask)] = True  # 返回上三角矩阵的索引\n",
    "\n",
    "plt.figure(figsize=(12,12))\n",
    "sns.heatmap(sq_dists, cmap=plt.get_cmap('viridis'), square=True, mask=mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**图像近邻**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "给定宫颈图像库和上面的相似性矩阵，我们现在将绘制相似性矩阵的极端情况。\n",
    "\n",
    "为此，我们找到具有以下内容的图像：\n",
    "- 与所有其他图像相比，具有平均最大距离的图像\n",
    "- 与所有其他图像相比，具有平均最小距离的图像\n",
    "- 并将这两个图像与来自一组的平均图像进行比较。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# upper triangle of matrix set to np.nan\n",
    "sq_dists[np.triu_indices_from(mask)] = np.nan\n",
    "sq_dists[0, 0] = np.nan\n",
    "\n",
    "fig = plt.figure(figsize=(12,8))\n",
    "# maximally dissimilar image\n",
    "ax = fig.add_subplot(1,3,1)\n",
    "maximally_dissimilar_image_idx = np.nanargmax(np.nanmean(sq_dists, axis=1))\n",
    "plt.imshow(all_images[maximally_dissimilar_image_idx])\n",
    "plt.title('maximally dissimilar')\n",
    "\n",
    "# maximally similar image\n",
    "ax = fig.add_subplot(1,3,2)\n",
    "maximally_similar_image_idx = np.nanargmin(np.nanmean(sq_dists, axis=1))\n",
    "plt.imshow(all_images[maximally_similar_image_idx])\n",
    "plt.title('maximally similar')\n",
    "\n",
    "# now compute the mean image\n",
    "ax = fig.add_subplot(1,3,3)\n",
    "mean_img = gray_imgs_mat.mean(axis=0).reshape(rescaled_dim, rescaled_dim, 3)\n",
    "plt.imshow(cv2.normalize(mean_img, None, 0.0, 1.0, cv2.NORM_MINMAX))\n",
    "plt.title('mean image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "左边的图像有很多蓝色，我不希望它出现在大多数样本中。我认为这是“最大不同图像”的一个很好的描述方式。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4、模型选择"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在我们已经建立了关于数据的基本概念，接下来用最简单的方法，我们将调整彩色图像的大小和标签，并训练一个简单的线性模型，如逻辑回归。\n",
    "\n",
    "理解这一点非常重要，我们只查看了一些训练实例，108个，并有数千个维度。为了能够应对，我们很可能会使用L1正则化。\n",
    "\n",
    "对于我们所面临的多类问题，我们将使用**OVR的标准方法(one vs rest)**，这意味着我们将训练三个模型，其中每个模型分别用于区分第1类、第2类和第3类。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import Normalizer\n",
    "y = LabelEncoder().fit_transform(all_image_types).reshape(-1)  # LabelEncoder：在0和n_class-1之间对标签进行编码\n",
    "X = gray_imgs_mat # no need for normalizing, we already did this earlier Normalizer().fit_transform(gray_imgs_mat)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = LogisticRegression()\n",
    "grid = {\n",
    "    'C': [1e-9, 1e-6, 1e-3, 1e0],\n",
    "    'penalty': ['l1', 'l2']\n",
    "}\n",
    "# 多CPU\n",
    "cv = GridSearchCV(clf, grid, scoring='neg_log_loss', n_jobs=-1, verbose=1)\n",
    "cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(1, len(cv.cv_results_['params'])+1):\n",
    "    rank = cv.cv_results_['rank_test_score'][i-1]\n",
    "    s = cv.cv_results_['mean_test_score'][i-1]\n",
    "    sd = cv.cv_results_['std_test_score'][i-1]\n",
    "    params = cv.cv_results_['params'][i-1]\n",
    "    print(\"{0}. Mean validation neg log loss: {1:.6f} (std: {2:.6f}) - {3}\".format(\n",
    "        rank,\n",
    "        s,\n",
    "        sd,\n",
    "        params\n",
    "    ))\n",
    "    \n",
    "print('AFTER LR Parameters: ', cv.best_params_)\n",
    "print(\"AFTER LR Training w/bin score mean: {:.2f}\". format(cv.cv_results_['mean_train_score'][cv.best_index_]*100)) \n",
    "print(\"AFTER LR Test w/bin score mean: {:.2f}\". format(cv.cv_results_['mean_test_score'][cv.best_index_]*100))\n",
    "print(\"AFTER LR Test w/bin score 3*std: +/- {:.2f}\". format(cv.cv_results_['std_test_score'][cv.best_index_]*100*3))\n",
    "print('-'*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test_hat_p = cv.predict_proba(X_test)  # 分类概率矩阵，每行和为1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "sns.distplot(y_test_hat_p[:,0], color='red')\n",
    "sns.distplot(y_test_hat_p[:,1], color='blue')\n",
    "sns.distplot(y_test_hat_p[:,2], color='green')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfy = pd.DataFrame({'0': y_test_hat_p[:,0], '1': y_test_hat_p[:,1], '2': y_test_hat_p[:,2]})\n",
    "sns.pairplot(dfy) # 多变量图"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 混淆矩阵"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "混淆矩阵是二分类和多分类问题中一个标准的分析工具，在每个条目中，C_{i,j}对应的是具有正确类标签i并被预测为j的样本数目，。\n",
    "\n",
    "我们可以看到，我们的模型有一个很大的问题，混淆了类0和类2。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_test_hat = cv.predict(X_test)\n",
    "\n",
    "data = [\n",
    "    go.Heatmap(\n",
    "        z=confusion_matrix(y_test, y_test_hat),\n",
    "        x=[0, 1, 2],\n",
    "        y=[0, 1, 2],\n",
    "        colorscale='Viridis',\n",
    "        text = True ,\n",
    "        opacity = 1.0\n",
    "    )\n",
    "]\n",
    "\n",
    "layout = go.Layout(\n",
    "    title='Test Confusion matrix',\n",
    "    xaxis = dict(ticks='', nticks=36),\n",
    "    yaxis = dict(ticks='' ),\n",
    "    width = 900, height = 700,\n",
    "    \n",
    ")\n",
    "\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig, filename='labelled-heatmap')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**混淆矩阵在训练集上**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_train_hat = cv.predict(X_train)\n",
    "\n",
    "data = [\n",
    "    go.Heatmap(\n",
    "        z=confusion_matrix(y_train, y_train_hat),\n",
    "        x=[0, 1, 2],\n",
    "        y=[0, 1, 2],\n",
    "        colorscale='Viridis',\n",
    "        text = True ,\n",
    "        opacity = 1.0\n",
    "    )\n",
    "]\n",
    "\n",
    "layout = go.Layout(\n",
    "    title='Training Confusion matrix',\n",
    "    xaxis = dict(ticks='', nticks=36),\n",
    "    yaxis = dict(ticks='' ),\n",
    "    width = 900, height = 700,\n",
    "    \n",
    ")\n",
    "\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig, filename='labelled-heatmap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "查看训练集上的混淆矩阵，我们可以看到，我们几乎只预测了类1。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
